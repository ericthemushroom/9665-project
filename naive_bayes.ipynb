{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 1:\n",
    "    train = pd.read_csv('C:/Users/eric the cool/Desktop/9665/project/SMS_train.csv', encoding = 'latin-1')\n",
    "    test = pd.read_csv('C:/Users/eric the cool/Desktop/9665/project/SMS_test.csv', encoding = 'latin-1')\n",
    "    train['Label'] =  train['Label'].map({\"Non-Spam\":0,\"Spam\":1})\n",
    "    test['Label'] =  test['Label'].map({\"Non-Spam\":0,\"Spam\":1})\n",
    "\n",
    "if dataset == 2:\n",
    "    data = pd.read_csv('C:/Users/eric the cool/Desktop/9665/project/spam_ham_dataset.csv', encoding = 'latin-1')\n",
    "    data = data.rename(columns={'label_num': 'Label', 'text': 'Message_body'})\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train, test = train_test_split(data, test_size=0.2, random_state=0)\n",
    "    train = train[['Message_body', 'Label']]\n",
    "    test = test[['Message_body', 'Label']]\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing (text):\n",
    "    \n",
    "    ps = nltk.stem.PorterStemmer()\n",
    "    # Normalization and cleaning\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(http|https|www)(:|\\.)\\S+.com\",\" \",text)\n",
    "    text = re.sub('[^a-zA-Z0-9\\n]', ' ', text)\n",
    "    text = re.sub(\"[^\\w\\d]\",\" \",text)\n",
    "    text = re.sub(\"\\d+\",\" \",text)\n",
    "    text = re.sub('\\s+',' ', text)\n",
    "    text = \" \".join([ps.stem(t) for t in text.split() if t not in nltk.corpus.stopwords.words(\"english\")])\n",
    "    \n",
    "    # Tokenization and Stemming\n",
    "#     token_text = []\n",
    "#     ps = nltk.stem.PorterStemmer()\n",
    "#     for word in nltk.word_tokenize(text):\n",
    "#         token_text.append(ps.stem(word))\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = []\n",
    "for i in range(train.shape[0]):\n",
    "    processed_text.append(preprocessing(train.loc[i].at[\"Message_body\"]))\n",
    "    \n",
    "train['processed_text'] = processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text2 = []\n",
    "for i in range(test.shape[0]):\n",
    "    processed_text2.append(preprocessing(test['Message_body'][i]))\n",
    "    \n",
    "test['processed_text'] = processed_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject natur ga nomin enron methanol nomin follow natur ga requir methanol plant august mmbtu per day egpfc nomin follow natur ga requir mtbe plant morgan point august mmbtu per day'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['processed_text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4136"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: meter 986296\\r\\nscherlyn , per our co...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject meter scherlyn per convers meter month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: natural gas nomination for 08 / 00\\r\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject natur ga nomin enron methanol nomin fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: cleburne outage\\r\\ngentlemen ,\\r\\ni w...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject cleburn outag gentlemen want clarifi l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: daren ,\\r\\nthe firm trading waha book...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject daren firm trade waha book set intern ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : mon , 2 feb 2004 03 : 16 : 16 - ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject mon feb page load imag show view messa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Message_body  Label  \\\n",
       "0  Subject: meter 986296\\r\\nscherlyn , per our co...      0   \n",
       "1  Subject: natural gas nomination for 08 / 00\\r\\...      0   \n",
       "2  Subject: cleburne outage\\r\\ngentlemen ,\\r\\ni w...      0   \n",
       "3  Subject: daren ,\\r\\nthe firm trading waha book...      0   \n",
       "4  Subject: re : mon , 2 feb 2004 03 : 16 : 16 - ...      1   \n",
       "\n",
       "                                      processed_text  \n",
       "0  subject meter scherlyn per convers meter month...  \n",
       "1  subject natur ga nomin enron methanol nomin fo...  \n",
       "2  subject cleburn outag gentlemen want clarifi l...  \n",
       "3  subject daren firm trade waha book set intern ...  \n",
       "4  subject mon feb page load imag show view messa...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(dialogue_act_features(train['processed_text'][i]), train['Label'][i])\n",
    "              for i in range(len(train['processed_text']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = [(dialogue_act_features(test['processed_text'][i]), test['Label'][i])\n",
    "              for i in range(len(test['processed_text']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9352657004830918\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(subject)': True,\n",
       " 'contains(feb)': True,\n",
       " 'contains(intercompani)': True,\n",
       " 'contains(accrual)': True,\n",
       " 'contains(varianc)': True,\n",
       " 'contains(list)': True,\n",
       " 'contains(sitara)': True,\n",
       " 'contains(deal)': True,\n",
       " 'contains(volum)': True,\n",
       " 'contains(one)': True,\n",
       " 'contains(side)': True,\n",
       " 'contains(purchas)': True,\n",
       " 'contains(sale)': True,\n",
       " 'contains(get)': True,\n",
       " 'contains(accru)': True,\n",
       " 'contains(goal)': True,\n",
       " 'contains(bring)': True,\n",
       " 'contains(everyon)': True,\n",
       " 'contains(attent)': True,\n",
       " 'contains(second)': True,\n",
       " 'contains(see)': True,\n",
       " 'contains(solut)': True,\n",
       " 'contains(take)': True,\n",
       " 'contains(simplist)': True,\n",
       " 'contains(approach)': True,\n",
       " 'contains(sinc)': True,\n",
       " 'contains(nomin)': True,\n",
       " 'contains(match)': True,\n",
       " 'contains(month)': True,\n",
       " 'contains(end)': True,\n",
       " 'contains(wrong)': True,\n",
       " 'contains(assumpt)': True,\n",
       " 'contains(system)': True,\n",
       " 'contains(limit)': True,\n",
       " 'contains(free)': True,\n",
       " 'contains(suggest)': True,\n",
       " 'contains(idea)': True,\n",
       " 'contains(resolut)': True,\n",
       " 'contains(pleas)': True,\n",
       " 'contains(feel)': True,\n",
       " 'contains(give)': True,\n",
       " 'contains(call)': True,\n",
       " 'contains(hplc)': True,\n",
       " 'contains(sell)': True,\n",
       " 'contains(ena)': True,\n",
       " 'contains(product)': True,\n",
       " 'contains(febo)': True,\n",
       " 'contains(meter)': True,\n",
       " 'contains(point)': True,\n",
       " 'contains(amount)': True,\n",
       " 'contains(hpl)': True,\n",
       " 'contains(vol)': True,\n",
       " 'contains(var)': True,\n",
       " 'contains(mmbtu)': True,\n",
       " 'contains(midt)': True,\n",
       " 'contains(miss)': True,\n",
       " 'contains(hgpl)': True,\n",
       " 'contains(lone)': True,\n",
       " 'contains(total)': True,\n",
       " 'contains(mission)': True,\n",
       " 'contains(proactiv)': True,\n",
       " 'contains(identifi)': True,\n",
       " 'contains(resolv)': True,\n",
       " 'contains(issu)': True,\n",
       " 'contains(upstream)': True,\n",
       " 'contains(first)': True,\n",
       " 'contains(tie)': True,\n",
       " 'contains(monthli)': True,\n",
       " 'contains(actual)': True,\n",
       " 'contains(third)': True,\n",
       " 'contains(minim)': True,\n",
       " 'contains(analys)': True,\n",
       " 'contains(time)': True,\n",
       " 'contains(save)': True,\n",
       " 'contains(thank)': True,\n",
       " 'contains(gregg)': True,\n",
       " 'contains(lenart)': True,\n",
       " 'contains(texa)': True,\n",
       " 'contains(ga)': True,\n",
       " 'contains(settlement)': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.classify(testset[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [classifier.classify(testset[i][0]) for i in range(len(testset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[672,  60],\n",
       "       [  7, 296]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test['Label'], predictions, labels=None, sample_weight=None, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8314606741573034, 0.976897689768977, 0.898330804248862, None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(test['Label'], predictions,\n",
    "                                average = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
