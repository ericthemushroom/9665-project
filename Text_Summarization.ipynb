{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtext = \"Dear Sean, How are you? This is from the Baruch College Admission Office. I am writing to let you know that you tuition check did not go through. The courses that you registered is now on hold. If you still want to enroll this semester, please pay the tuition by the end of this week. Otherwise, You will be suspended. Please let us know as soon as possible. Let me know if you have any questions. You can call us at 999-000-000. Thank you and have a nice day.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(rawtext)\n",
    "num_sent = len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dear Sean, How are you?', 'This is from the Baruch College Admission Office.', 'I am writing to let you know that you tuition check did not go through.', 'The courses that you registered is now on hold.', 'If you still want to enroll this semester, please pay the tuition by the end of this week.', 'Otherwise, You will be suspended.', 'Please let us know as soon as possible.', 'Let me know if you have any questions.', 'You can call us at 999-000-000.', 'Thank you and have a nice day.']\n"
     ]
    }
   ],
   "source": [
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing (text):\n",
    "    \n",
    "    # Normalization and cleaning\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(http|https|www)(:|\\.)\\S+.com\",\" \",text)\n",
    "    text = re.sub(\"[^\\w\\d]\",\" \",text)\n",
    "    text = re.sub(\"\\d+\",\" \",text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sents = [preprocessing(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dear sean  how are you ', 'this is from the baruch college admission office ', 'i am writing to let you know that you tuition check did not go through ', 'the courses that you registered is now on hold ', 'if you still want to enroll this semester  please pay the tuition by the end of this week ', 'otherwise  you will be suspended ', 'please let us know as soon as possible ', 'let me know if you have any questions ', 'you can call us at       ', 'thank you and have a nice day ']\n"
     ]
    }
   ],
   "source": [
    "print(processed_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "w2v = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vectorize(post):\n",
    "    vec_size = w2v.vector_size\n",
    "    sent_vec = np.zeros(vec_size)\n",
    "    vec_count = 1\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        if word not in nltk.corpus.stopwords.words('english') and lemmatizer.lemmatize(word) in w2v:\n",
    "            vec_count += 1\n",
    "            sent_vec += w2v[lemmatizer.lemmatize(word)]\n",
    "    sent_vec = sent_vec/vec_count          \n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sents = [sent_vectorize(sent) for sent in processed_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cos similarity matrix and angle similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import math\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros([len(vectorized_sents), len(vectorized_sents)])\n",
    "angle_matrix = np.zeros([len(vectorized_sents), len(vectorized_sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(vectorized_sents):\n",
    "    for j, col in enumerate(vectorized_sents):\n",
    "        similarity_matrix[i][j] = 1 - spatial.distance.cosine(row,col)\n",
    "        angle_matrix[i][j] = math.acos(1 - spatial.distance.cosine(row,col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. W2V + Page Rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.08389246188711963, 1: 0.08630959825954422, 2: 0.12309747736748654, 3: 0.0872070162721341, 4: 0.11641747079461795, 5: 0.07148485651555794, 6: 0.1225584079547313, 7: 0.11435838627167476, 8: 0.09893105363109449, 9: 0.09574327104603897}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 1/num_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sent_keys=sorted([x for x in scores if scores[x]>=cutoff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am writing to let you know that you tuition check did not go through.\n",
      "If you still want to enroll this semester, please pay the tuition by the end of this week.\n",
      "Please let us know as soon as possible.\n",
      "Let me know if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "for id in top_sent_keys:\n",
    "    print(sents[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. W2V + Radian Distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(len(vectorized_sents)):\n",
    "               for j in range(len(vectorized_sents)):\n",
    "                              sum = sum + angle_matrix[i][j]\n",
    "                \n",
    "cutoff_angle = sum /(2*n_pair)\n",
    "n_pair = (num_sent**2-num_sent)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_scores = [angle_matrix[i].sum()/(num_sent-1) for i in range(len(vectorized_sents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sent_keys_angle =sorted([i for i in range(num_sent) if angle_scores[i]<=cutoff_angle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am writing to let you know that you tuition check did not go through.\n",
      "If you still want to enroll this semester, please pay the tuition by the end of this week.\n",
      "Please let us know as soon as possible.\n",
      "Let me know if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "for id in top_sent_keys_angle:\n",
    "    print(sents[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "sentences = nltk.sent_tokenize(rawtext) # NLTK function\n",
    "total_documents = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dear Sean, How ': {'dear': 1, 'sean': 1, ',': 1, '?': 1}, 'This is from th': {'thi': 1, 'baruch': 1, 'colleg': 1, 'admiss': 1, 'offic': 1, '.': 1}, 'I am writing to': {'write': 1, 'let': 1, 'know': 1, 'tuition': 1, 'check': 1, 'go': 1, '.': 1}, 'The courses tha': {'cours': 1, 'regist': 1, 'hold': 1, '.': 1}, 'If you still wa': {'still': 1, 'want': 1, 'enrol': 1, 'thi': 2, 'semest': 1, ',': 1, 'pleas': 1, 'pay': 1, 'tuition': 1, 'end': 1, 'week': 1, '.': 1}, 'Otherwise, You ': {'otherwis': 1, ',': 1, 'suspend': 1, '.': 1}, 'Please let us k': {'pleas': 1, 'let': 1, 'us': 1, 'know': 1, 'soon': 1, 'possibl': 1, '.': 1}, 'Let me know if ': {'let': 1, 'know': 1, 'ani': 1, 'question': 1, '.': 1}, 'You can call us': {'call': 1, 'us': 1, '999-000-000': 1, '.': 1}, 'Thank you and h': {'thank': 1, 'nice': 1, 'day': 1, '.': 1}}\n"
     ]
    }
   ],
   "source": [
    "freq_matrix = _create_frequency_matrix(sentences)\n",
    "print(freq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dear Sean, How ': {'dear': 0.25, 'sean': 0.25, ',': 0.25, '?': 0.25}, 'This is from th': {'thi': 0.16666666666666666, 'baruch': 0.16666666666666666, 'colleg': 0.16666666666666666, 'admiss': 0.16666666666666666, 'offic': 0.16666666666666666, '.': 0.16666666666666666}, 'I am writing to': {'write': 0.14285714285714285, 'let': 0.14285714285714285, 'know': 0.14285714285714285, 'tuition': 0.14285714285714285, 'check': 0.14285714285714285, 'go': 0.14285714285714285, '.': 0.14285714285714285}, 'The courses tha': {'cours': 0.25, 'regist': 0.25, 'hold': 0.25, '.': 0.25}, 'If you still wa': {'still': 0.08333333333333333, 'want': 0.08333333333333333, 'enrol': 0.08333333333333333, 'thi': 0.16666666666666666, 'semest': 0.08333333333333333, ',': 0.08333333333333333, 'pleas': 0.08333333333333333, 'pay': 0.08333333333333333, 'tuition': 0.08333333333333333, 'end': 0.08333333333333333, 'week': 0.08333333333333333, '.': 0.08333333333333333}, 'Otherwise, You ': {'otherwis': 0.25, ',': 0.25, 'suspend': 0.25, '.': 0.25}, 'Please let us k': {'pleas': 0.14285714285714285, 'let': 0.14285714285714285, 'us': 0.14285714285714285, 'know': 0.14285714285714285, 'soon': 0.14285714285714285, 'possibl': 0.14285714285714285, '.': 0.14285714285714285}, 'Let me know if ': {'let': 0.2, 'know': 0.2, 'ani': 0.2, 'question': 0.2, '.': 0.2}, 'You can call us': {'call': 0.25, 'us': 0.25, '999-000-000': 0.25, '.': 0.25}, 'Thank you and h': {'thank': 0.25, 'nice': 0.25, 'day': 0.25, '.': 0.25}}\n"
     ]
    }
   ],
   "source": [
    "tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "print(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():          # go through entire matrix, add 1 if catch\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dear': 1, 'sean': 1, ',': 3, '?': 1, 'thi': 2, 'baruch': 1, 'colleg': 1, 'admiss': 1, 'offic': 1, '.': 9, 'write': 1, 'let': 3, 'know': 3, 'tuition': 2, 'check': 1, 'go': 1, 'cours': 1, 'regist': 1, 'hold': 1, 'still': 1, 'want': 1, 'enrol': 1, 'semest': 1, 'pleas': 2, 'pay': 1, 'end': 1, 'week': 1, 'otherwis': 1, 'suspend': 1, 'us': 2, 'soon': 1, 'possibl': 1, 'ani': 1, 'question': 1, 'call': 1, '999-000-000': 1, 'thank': 1, 'nice': 1, 'day': 1}\n"
     ]
    }
   ],
   "source": [
    "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "print(count_doc_per_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dear Sean, How ': {'dear': 1.0, 'sean': 1.0, ',': 0.5228787452803376, '?': 1.0}, 'This is from th': {'thi': 0.6989700043360189, 'baruch': 1.0, 'colleg': 1.0, 'admiss': 1.0, 'offic': 1.0, '.': 0.04575749056067514}, 'I am writing to': {'write': 1.0, 'let': 0.5228787452803376, 'know': 0.5228787452803376, 'tuition': 0.6989700043360189, 'check': 1.0, 'go': 1.0, '.': 0.04575749056067514}, 'The courses tha': {'cours': 1.0, 'regist': 1.0, 'hold': 1.0, '.': 0.04575749056067514}, 'If you still wa': {'still': 1.0, 'want': 1.0, 'enrol': 1.0, 'thi': 0.6989700043360189, 'semest': 1.0, ',': 0.5228787452803376, 'pleas': 0.6989700043360189, 'pay': 1.0, 'tuition': 0.6989700043360189, 'end': 1.0, 'week': 1.0, '.': 0.04575749056067514}, 'Otherwise, You ': {'otherwis': 1.0, ',': 0.5228787452803376, 'suspend': 1.0, '.': 0.04575749056067514}, 'Please let us k': {'pleas': 0.6989700043360189, 'let': 0.5228787452803376, 'us': 0.6989700043360189, 'know': 0.5228787452803376, 'soon': 1.0, 'possibl': 1.0, '.': 0.04575749056067514}, 'Let me know if ': {'let': 0.5228787452803376, 'know': 0.5228787452803376, 'ani': 1.0, 'question': 1.0, '.': 0.04575749056067514}, 'You can call us': {'call': 1.0, 'us': 0.6989700043360189, '999-000-000': 1.0, '.': 0.04575749056067514}, 'Thank you and h': {'thank': 1.0, 'nice': 1.0, 'day': 1.0, '.': 0.04575749056067514}}\n"
     ]
    }
   ],
   "source": [
    "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "print(idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dear Sean, How ': {'dear': 0.25, 'sean': 0.25, ',': 0.1307196863200844, '?': 0.25}, 'This is from th': {'thi': 0.1164950007226698, 'baruch': 0.16666666666666666, 'colleg': 0.16666666666666666, 'admiss': 0.16666666666666666, 'offic': 0.16666666666666666, '.': 0.0076262484267791905}, 'I am writing to': {'write': 0.14285714285714285, 'let': 0.0746969636114768, 'know': 0.0746969636114768, 'tuition': 0.0998528577622884, 'check': 0.14285714285714285, 'go': 0.14285714285714285, '.': 0.0065367843658107345}, 'The courses tha': {'cours': 0.25, 'regist': 0.25, 'hold': 0.25, '.': 0.011439372640168786}, 'If you still wa': {'still': 0.08333333333333333, 'want': 0.08333333333333333, 'enrol': 0.08333333333333333, 'thi': 0.1164950007226698, 'semest': 0.08333333333333333, ',': 0.043573228773361464, 'pleas': 0.0582475003613349, 'pay': 0.08333333333333333, 'tuition': 0.0582475003613349, 'end': 0.08333333333333333, 'week': 0.08333333333333333, '.': 0.0038131242133895953}, 'Otherwise, You ': {'otherwis': 0.25, ',': 0.1307196863200844, 'suspend': 0.25, '.': 0.011439372640168786}, 'Please let us k': {'pleas': 0.0998528577622884, 'let': 0.0746969636114768, 'us': 0.0998528577622884, 'know': 0.0746969636114768, 'soon': 0.14285714285714285, 'possibl': 0.14285714285714285, '.': 0.0065367843658107345}, 'Let me know if ': {'let': 0.10457574905606754, 'know': 0.10457574905606754, 'ani': 0.2, 'question': 0.2, '.': 0.00915149811213503}, 'You can call us': {'call': 0.25, 'us': 0.17474250108400471, '999-000-000': 0.25, '.': 0.011439372640168786}, 'Thank you and h': {'thank': 0.25, 'nice': 0.25, 'day': 0.25, '.': 0.011439372640168786}}\n"
     ]
    }
   ],
   "source": [
    "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence   #sentence average\n",
    "\n",
    "    return sentenceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dear Sean, How ': 0.2201799215800211, 'This is from th': 0.13179798596935258, 'I am writing to': 0.09776499970321162, 'The courses tha': 0.1903598431600422, 'If you still wa': 0.07197580731378535, 'Otherwise, You ': 0.1605397647400633, 'Please let us k': 0.0916215304039467, 'Let me know if ': 0.12366059924485402, 'You can call us': 0.17154546843104337, 'Thank you and h': 0.1903598431600422}\n"
     ]
    }
   ],
   "source": [
    "sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "print(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14498057637063624\n"
     ]
    }
   ],
   "source": [
    "threshold = _find_average_score(sentence_scores)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=_generate_summary(sentences, sentence_scores, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dear Sean, How are you? The courses that you registered is now on hold. Otherwise, You will be suspended. You can call us at 999-000-000. Thank you and have a nice day.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
