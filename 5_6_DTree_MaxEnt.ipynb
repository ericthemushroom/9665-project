{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/eric the cool/Desktop/9665/project/spam_ham_dataset.csv', encoding = 'latin-1')\n",
    "data = data[['text', 'label_num']]\n",
    "data = data.rename(columns={'label_num': 'label'})\n",
    "\n",
    "random.seed(10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=0)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing (text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(http|https|www)(:|\\.)\\S+.com\",\" \",text)\n",
    "    text = re.sub('[^a-zA-Z0-9\\n]', ' ', text)\n",
    "    text = re.sub(\"[^\\w\\d]\",\" \",text)\n",
    "    text = re.sub(\"\\d+\",\" \",text)\n",
    "    text = re.sub('\\s+',' ', text)\n",
    "    text = \" \".join([lemmatizer.lemmatize(t) for t in text.split() if t not in nltk.corpus.stopwords.words(\"english\")])\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text_trn = []\n",
    "for i in range(train.shape[0]):\n",
    "    processed_text_trn.append(preprocessing(train['text'][i]))    \n",
    "train['processed_text'] = processed_text_trn\n",
    "\n",
    "processed_text_tst = []\n",
    "for i in range(test.shape[0]):\n",
    "    processed_text_tst.append(preprocessing(test['text'][i]))    \n",
    "test['processed_text'] = processed_text_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4136,)\n",
      "(4136,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train['processed_text']\n",
    "Y_train = train['Label']\n",
    "\n",
    "X_test = test['processed_text']\n",
    "Y_test = test['Label']\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text_vec = TfidfVectorizer(min_df=10, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = text_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        if word in feature_names:\n",
    "            features['contains({})'.format(word)] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset_train = [(extract_features(train['processed_text'][i]), train['label'][i])\n",
    "              for i in range(len(train['processed_text']))]\n",
    "\n",
    "featureset_test = [(extract_features(test['processed_text'][i]), test['label'][i])\n",
    "              for i in range(len(test['processed_text']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.DecisionTreeClassifier.train(featureset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9291586073500967\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, featureset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8908212560386474\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, featureset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[717,  15],\n",
       "       [ 98, 205]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [classifier.classify(featureset_test[i][0]) for i in range(len(featureset_test))]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test['label'], predictions, labels=None, sample_weight=None, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9318181818181818, 0.6765676567656765, 0.7839388145315488, None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(test['label'], predictions,\n",
    "                                average = 'binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision = 0.9318\n",
    "### Recall = 0.6766\n",
    "### F-score = 0.7839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (30 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.289\n",
      "             2          -0.31677        0.781\n",
      "             3          -0.24900        0.907\n",
      "             4          -0.21770        0.932\n",
      "             5          -0.19894        0.939\n",
      "             6          -0.18602        0.942\n",
      "             7          -0.17634        0.946\n",
      "             8          -0.16868        0.955\n",
      "             9          -0.16237        0.957\n",
      "            10          -0.15703        0.958\n",
      "            11          -0.15242        0.959\n",
      "            12          -0.14836        0.959\n",
      "            13          -0.14474        0.961\n",
      "            14          -0.14147        0.962\n",
      "            15          -0.13850        0.963\n",
      "            16          -0.13577        0.963\n",
      "            17          -0.13326        0.964\n",
      "            18          -0.13093        0.965\n",
      "            19          -0.12876        0.966\n",
      "            20          -0.12672        0.967\n",
      "            21          -0.12481        0.967\n",
      "            22          -0.12301        0.967\n",
      "            23          -0.12131        0.969\n",
      "            24          -0.11970        0.969\n",
      "            25          -0.11817        0.970\n",
      "            26          -0.11671        0.970\n",
      "            27          -0.11532        0.970\n",
      "            28          -0.11399        0.971\n",
      "            29          -0.11271        0.971\n",
      "         Final          -0.11149        0.972\n"
     ]
    }
   ],
   "source": [
    "ME_classifier = nltk.MaxentClassifier.train(featureset_train, max_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9717117988394585\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(ME_classifier, featureset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603864734299516\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(ME_classifier, featureset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[705,  27],\n",
       "       [ 14, 289]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [ME_classifier.classify(featureset_test[i][0]) for i in range(len(featureset_test))]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test['label'], predictions, labels=None, sample_weight=None, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9145569620253164, 0.9537953795379538, 0.9337641357027463, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(test['label'], predictions,\n",
    "                                average = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision = 0.9146\n",
    "### Recall = 0.9538\n",
    "### F-score = 0.9338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
